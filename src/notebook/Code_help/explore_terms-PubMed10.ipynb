{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PubMed10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "from DCC_data_utils import make_tfidf, make_PPMI\n",
    "import random\n",
    "\n",
    "n_top_terms = 50\n",
    "n_top_frequent = 5000\n",
    "n_runs = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PubMed original data\n",
    "PubMed10_dw = loadmat(\"/home/saffeldt/Projects/Projects_clustering/DCC/DataDCC/PubMed10/docWordMat.mat\")\n",
    "doc_term_counts = PubMed10_dw[\"docWordMat\"]\n",
    "PubMed10_lb = loadmat(\"/home/saffeldt/Projects/Projects_clustering/DCC/DataDCC/PubMed10/label.mat\")\n",
    "labels = PubMed10_lb[\"label\"]\n",
    "labels = [item for sublist in labels for item in sublist]\n",
    "\n",
    "# Apply the same permutations of rows as done before using RDCC\n",
    "tmp_perm = np.random.RandomState(seed=42).permutation(doc_term_counts.shape[0])\n",
    "doc_term_counts = doc_term_counts[tmp_perm,:]\n",
    "labels = [labels[i] for i in tmp_perm.tolist()]\n",
    "\n",
    "# Load the words and get the freq\n",
    "pm10_terms = loadmat(\"/home/saffeldt/Projects/Projects_clustering/DCC/DataDCC/PubMed10/wordList.mat\")\n",
    "##pm10_terms\n",
    "pm10_terms = pm10_terms[\"wordList\"]\n",
    "pm10_terms_list = list()\n",
    "\n",
    "for i in range(pm10_terms.shape[0]):\n",
    "    pm10_terms_list.append(pm10_terms[i,0].tolist()[0])\n",
    "\n",
    "pm10_terms = pm10_terms_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ---------------\n",
      "# TF-IDF transform\n",
      "# ---------------\n",
      "# X_tfidf shape: (15565, 22437)\n",
      "\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "# X_tfidf min/max: 0.0, 0.9381604331034942\n",
      "# X_tfidf sparsity: 0.9972514825070178\n",
      "# ---------------\n",
      "(22437, 15565)\n",
      "(15565, 22437)\n",
      "(22437, 1)\n",
      "(1, 22437)\n",
      "--1-- 12373080\n",
      "--2-- 8947114\n",
      "# ---------------\n",
      "# SPPMI transform from X_TFIDF\n",
      "# ---------------\n",
      "# SPPMI shape: (22437, 22437)\n",
      "\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "\n",
      "# SPPMI min/max: 0.0, 11.7435\n",
      "# SPPMI sparsity: 0.9822\n",
      "# ---------------\n"
     ]
    }
   ],
   "source": [
    "# Make the TF-IDF matrix\n",
    "my_norm = 'l2'\n",
    "s_idf = True\n",
    "s_tf = False\n",
    "mat_tfidf = make_tfidf(doc_term_counts, data_name = \"PubMed10\", \n",
    "                       norm = my_norm,\n",
    "                       smooth_idf = s_idf, sublinear_tf = s_tf, \n",
    "                       verbose = True)\n",
    "\n",
    "# Make the word PPMI matrix\n",
    "isCol = True\n",
    "mat_ppmi = make_PPMI(mat_tfidf, isCol = isCol, verbose = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute a reference PPMI mean value (random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median PPMI 0.18169191795372383\n",
      "Max PPMI 0.2504488839806242\n",
      "Min PPMI 0.11680503330235176\n",
      "\n",
      "Mean PPMI 0.18171580133203658\n",
      "--> PPMI std 0.020300961455491134\n"
     ]
    }
   ],
   "source": [
    "all_rand_mean_ppmi = list()\n",
    "\n",
    "# Get randomly n_top_terms words among the n_top_frequent terms\n",
    "terms_freq = (doc_term_counts.sum(axis=0))\n",
    "# Sort by decreasing count sum\n",
    "terms_freq_order = np.array((-terms_freq).argsort()).flatten().tolist()\n",
    "\n",
    "for iRun in range(n_runs):\n",
    "    rand_idx = random.sample(range(0, n_top_frequent), n_top_terms)\n",
    "    terms_freq_ref = [terms_freq_order[i] for i in rand_idx]\n",
    "    #print(terms_freq_ref)\n",
    "\n",
    "    # Get the corresponding TF-IDF vector\n",
    "    #mat_tfidf_mostFreq = mat_tfidf[:,terms_freq_order[:n_terms]]\n",
    "    mat_ppmi_mostFreq = mat_ppmi[:,terms_freq_ref]\n",
    "    mat_ppmi_mostFreq = mat_ppmi_mostFreq[terms_freq_ref, :]\n",
    "    #print(mat_ppmi_mostFreq.shape)\n",
    "\n",
    "    # Compute the mean PPMI\n",
    "    #print(mat_ppmi_mostFreq)\n",
    "    tmp_list = []\n",
    "    for i in range(mat_ppmi_mostFreq.shape[0]):\n",
    "        for j in range(i+1, mat_ppmi_mostFreq.shape[1]):\n",
    "            tmp_list.append(mat_ppmi_mostFreq[i,j])\n",
    "    tmp_mean = np.mean(tmp_list)\n",
    "    all_rand_mean_ppmi.append(tmp_mean)\n",
    "    \n",
    "print(\"Median PPMI\", np.median(all_rand_mean_ppmi))\n",
    "print(\"Max PPMI\", np.max(all_rand_mean_ppmi))\n",
    "print(\"Min PPMI\", np.min(all_rand_mean_ppmi))\n",
    "print(\"\\nMean PPMI\", np.mean(all_rand_mean_ppmi))\n",
    "print(\"--> PPMI std\", np.std(all_rand_mean_ppmi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMI 0.6343\n",
      "ARI 0.5625\n",
      "n_clust 0 ( row 2559 )\n",
      "-->> PPMI: 0.6418274436799918\n",
      "['antigout', 'gout', 'gouti', 'pseudogout']\n",
      "['jaundic']\n",
      "['calculi', 'microcalculi']\n",
      "['extrahepat', 'hepatectomi', 'hepati', 'hepatica', 'hepaticojejunostomi', 'hepatobiliari', 'hepatocellular', 'hepatocyt', 'hepatoduoden', 'hepatolog', 'hepatomegali', 'hepatopet', 'hepatoportoenterostomi', 'hepatoprotect', 'hepatoren', 'hepatotox', 'hepatotoxicti', 'intrahepat', 'posthepat', 'posthepatectomi', 'prehepat', 'steatohepat', 'subhepat', 'transhepat', 'transhepatich']\n",
      "4538\n",
      "--> ['wa' 'patient' 'stone' 'renal' 'group' 'calcium' 'urinari' 'kidnei'\n",
      " 'oxal' 'gout' 'level' 'rate' 'crystal' 'present' 'percutan' 'urin'\n",
      " 'obstruct' 'acid' 'jaundic' 'lower' 'calculi' 'serum' 'report' 'perform'\n",
      " 'uric' 'cau' 'shock' 'wave' 'lithotripsi' 'requir'] \n",
      "\n",
      "n_clust 1 ( row 2401 )\n",
      "-->> PPMI: 0.5254552715034845\n",
      "['goutlik', 'nongout']\n",
      "['almotriptan', 'eletriptan', 'frovatriptan', 'naratriptan', 'nontriptan', 'notriptan', 'rizatriptan', 'sumatriptan', 'triptan', 'zolmitriptan', 'zomitriptan']\n",
      "['antichickenpox']\n",
      "['cyprohepatin']\n",
      "['allergan', 'allergina']\n",
      "2634\n",
      "--> ['headach' 'treatment' 'studi' 'thi' 'ar' 'effect' 'clinic' 'pain' 'than'\n",
      " 'compar' 'mg' 'medic' 'attack' 'efficaci' 'sever' 'trial' 'assess'\n",
      " 'placebo' 'treat' 'sumatriptan' 'includ' 'data' 'respon' 'drug' 'evalu'\n",
      " 'triptan' 'adver' 'dose' 'prevent' 'hour'] \n",
      "\n",
      "n_clust 2 ( row 1600 )\n",
      "-->> PPMI: 0.8414240332355829\n",
      "['chickenpox']\n",
      "['antihepat', 'hepat', 'hepatoma', 'hepatopathi', 'hepatosplenomegali', 'hepatotrop', 'nonhepat']\n",
      "2065\n",
      "--> ['vaccin' 'hepat' 'varicella' 'infect' 'viru' 'ag' 'hav' 'year' 'immun'\n",
      " 'antibodi' 'preval' 'cost' 'vzv' 'incid' 'develop' 'sampl' 'popul'\n",
      " 'outbreak' 'posit' 'zoster' 'hospit' 'seroprev' 'high' 'detect' 'viral'\n",
      " 'estim' 'adult' 'histori' 'occur' 'recommend'] \n",
      "\n",
      "n_clust 3 ( row 2562 )\n",
      "-->> PPMI: 0.8237628634335469\n",
      "['agouti']\n",
      "['epimacular', 'foveomacular', 'interpapillomacular', 'macular', 'maculari', 'papillomacular', 'paramacular', 'perimacular', 'premacular', 'submacular', 'vitreomacular']\n",
      "3082\n",
      "--> ['macular' 'ey' 'visual' 'retin' 'acuiti' 'amd' 'month' 'diabet' 'improv'\n",
      " 'degen' 'neovascular' 'no' 'signif' 'edema' 'intravitr' 'increa' 'thick'\n",
      " 'choroid' 'inject' 'risk' 'measur' 'laser' 'chang' 'outcom' 'cnv' 'earli'\n",
      " 'optic' 'baselin' 'vision' 'therapi'] \n",
      "\n",
      "n_clust 4 ( row 1434 )\n",
      "-->> PPMI: 1.0664838897801625\n",
      "['aeroallergen', 'allerg', 'allergen', 'allergi', 'allergica', 'allergist', 'allergoid', 'allergolog', 'allergopharma', 'allergosorb', 'allergovit', 'antiallerg', 'antiallergi', 'dermatoallerg', 'hypoallerg', 'hypoallergen', 'multiallergosorb', 'nonallerg', 'nonallergen', 'nonallergi', 'nonallergist', 'panallergen', 'postallergen', 'radioallergosorb', 'stallergen']\n",
      "2246\n",
      "--> ['allerg' 'nasal' 'rhiniti' 'symptom' 'pollen' 'season' 'allergen'\n",
      " 'asthma' 'significantli' 'subject' 'score' 'cell' 'ig' 'sensit' 'test'\n",
      " 'allergi' 'specif' 'total' 'grass' 'immunotherapi' 'eosinophil' 'reduc'\n",
      " 'intrana' 'challeng' 'daili' 'airwai' 'skin' 'befor' 'exposur' 'sar'] \n",
      "\n",
      "n_clust 5 ( row 2327 )\n",
      "-->> PPMI: 0.9421459034538578\n",
      "['otiti', 'otitidi', 'otitispron']\n",
      "['cholangiohepat']\n",
      "['immunoallerg']\n",
      "3663\n",
      "--> ['otiti' 'ear' 'children' 'media' 'middl' 'acut' 'antibiot' 'tube' 'aom'\n",
      " 'hear' 'case' 'chronic' 'effu' 'om' 'result' 'dai' 'isol' 'recurr'\n",
      " 'pneumonia' 'bacteri' 'tympan' 'mastoid' 'complic' 'pneumococc'\n",
      " 'influenza' 'onli' 'pathogen' 'episod' 'resist' 'membran'] \n",
      "\n",
      "n_clust 6 ( row 2682 )\n",
      "-->> PPMI: 0.4157658302712962\n",
      "['donitriptan']\n",
      "['raynaud']\n",
      "['hepatopulmonari', 'hepatoviru']\n",
      "['extramacular', 'maculardegen']\n",
      "4209\n",
      "--> ['migrain' 'associ' 'gene' 'control' 'mai' 'aura' 'differ' 'dure' 'mutat'\n",
      " 'famili' 'suggest' 'disea' 'ha' 'show' 'genet' 'activ' 'factor' 'found'\n",
      " 'polymorph' 'blood' 'investig' 'identifi' 'role' 'involv' 'analysi'\n",
      " 'mechan' 'affect' 'evid' 'healthi' 'allel'] \n",
      "\n",
      "              0            1          2            3              4  \\\n",
      "0            wa      headach     vaccin      macular         allerg   \n",
      "1       patient    treatment      hepat           ey          nasal   \n",
      "2         stone        studi  varicella       visual        rhiniti   \n",
      "3         renal          thi     infect        retin        symptom   \n",
      "4         group           ar       viru       acuiti         pollen   \n",
      "5       calcium       effect         ag          amd         season   \n",
      "6       urinari       clinic        hav        month       allergen   \n",
      "7        kidnei         pain       year       diabet         asthma   \n",
      "8          oxal         than      immun       improv  significantli   \n",
      "9          gout       compar   antibodi        degen        subject   \n",
      "10        level           mg     preval  neovascular          score   \n",
      "11         rate        medic       cost           no           cell   \n",
      "12      crystal       attack        vzv       signif             ig   \n",
      "13      present     efficaci      incid        edema         sensit   \n",
      "14     percutan        sever    develop    intravitr           test   \n",
      "15         urin        trial      sampl       increa        allergi   \n",
      "16     obstruct       assess      popul        thick         specif   \n",
      "17         acid      placebo   outbreak      choroid          total   \n",
      "18      jaundic        treat      posit       inject          grass   \n",
      "19        lower  sumatriptan     zoster         risk  immunotherapi   \n",
      "20      calculi       includ     hospit       measur     eosinophil   \n",
      "21        serum         data   seroprev        laser          reduc   \n",
      "22       report       respon       high        chang        intrana   \n",
      "23      perform         drug     detect       outcom       challeng   \n",
      "24         uric        evalu      viral          cnv          daili   \n",
      "25          cau      triptan      estim        earli         airwai   \n",
      "26        shock        adver      adult        optic           skin   \n",
      "27         wave         dose    histori      baselin          befor   \n",
      "28  lithotripsi      prevent      occur       vision        exposur   \n",
      "29       requir         hour  recommend      therapi            sar   \n",
      "\n",
      "             5          6  \n",
      "0        otiti    migrain  \n",
      "1          ear     associ  \n",
      "2     children       gene  \n",
      "3        media    control  \n",
      "4        middl        mai  \n",
      "5         acut       aura  \n",
      "6     antibiot     differ  \n",
      "7         tube       dure  \n",
      "8          aom      mutat  \n",
      "9         hear     famili  \n",
      "10        case    suggest  \n",
      "11     chronic      disea  \n",
      "12        effu         ha  \n",
      "13          om       show  \n",
      "14      result      genet  \n",
      "15         dai      activ  \n",
      "16        isol     factor  \n",
      "17      recurr      found  \n",
      "18   pneumonia  polymorph  \n",
      "19     bacteri      blood  \n",
      "20      tympan   investig  \n",
      "21     mastoid   identifi  \n",
      "22     complic       role  \n",
      "23  pneumococc     involv  \n",
      "24   influenza    analysi  \n",
      "25        onli     mechan  \n",
      "26    pathogen     affect  \n",
      "27      episod       evid  \n",
      "28      resist    healthi  \n",
      "29     membran      allel  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "\n",
    "all_top_terms = list()\n",
    "all_top_terms_idx = list()\n",
    "\n",
    "final_k = 7\n",
    "\n",
    "# nClust = 10\n",
    "if final_k == 10:\n",
    "    col_part = np.load(\"/home/saffeldt/Projects/Projects_clustering/DCC/output/PubMed10/EBCO_1init_24runs_p0_id_nClust_diverse_exploreWords/final_k_given_10_064_054/W_0.25mod_l2_sidfTrue_stfFalse_k10_stoch70_init1_iter100.npy\")\n",
    "    row_part = np.load(\"/home/saffeldt/Projects/Projects_clustering/DCC/output/PubMed10/EBCO_1init_24runs_p0_id_nClust_diverse_exploreWords/final_k_given_10_064_054/Z_0.25mod_l2_sidfTrue_stfFalse_k10_stoch70_init1_iter100.npy\")\n",
    "# nClust = 9\n",
    "elif final_k == 9:\n",
    "    col_part = np.load(\"/home/saffeldt/Projects/Projects_clustering/DCC/output/PubMed10/EBCO_1init_24runs_p0_id_nClust_diverse_exploreWords/final_k_given_9_063_053/W_0.25mod_l2_sidfTrue_stfFalse_k10_stoch70_init1_iter100.npy\")\n",
    "    row_part = np.load(\"/home/saffeldt/Projects/Projects_clustering/DCC/output/PubMed10/EBCO_1init_24runs_p0_id_nClust_diverse_exploreWords/final_k_given_9_063_053/Z_0.25mod_l2_sidfTrue_stfFalse_k10_stoch70_init1_iter100.npy\")\n",
    "# nClust = 8\n",
    "elif final_k == 8:\n",
    "    col_part = np.load(\"/home/saffeldt/Projects/Projects_clustering/DCC/output/PubMed10/EBCO_1init_24runs_p0_id_nClust_diverse_exploreWords/final_k_given_8_063_053/W_0.25mod_l2_sidfTrue_stfFalse_k10_stoch70_init1_iter100.npy\")\n",
    "    row_part = np.load(\"/home/saffeldt/Projects/Projects_clustering/DCC/output/PubMed10/EBCO_1init_24runs_p0_id_nClust_diverse_exploreWords/final_k_given_8_063_053/Z_0.25mod_l2_sidfTrue_stfFalse_k10_stoch70_init1_iter100.npy\")\n",
    "# nClust = 7\n",
    "elif final_k == 7:\n",
    "    col_part = np.load(\"/home/saffeldt/Projects/Projects_clustering/DCC/output/PubMed10/EBCO_1init_24runs_p0_id_nClust_diverse_exploreWords/final_k_given_7_063_056/W_0.25mod_l2_sidfTrue_stfFalse_k10_stoch70_init1_iter100.npy\")\n",
    "    row_part = np.load(\"/home/saffeldt/Projects/Projects_clustering/DCC/output/PubMed10/EBCO_1init_24runs_p0_id_nClust_diverse_exploreWords/final_k_given_7_063_056/Z_0.25mod_l2_sidfTrue_stfFalse_k10_stoch70_init1_iter100.npy\")\n",
    "\n",
    "col_part = col_part.flatten()\n",
    "row_part = row_part.flatten()\n",
    "\n",
    "ari = adjusted_rand_score(labels, row_part)\n",
    "nmi = normalized_mutual_info_score(labels, row_part, average_method=\"arithmetic\")\n",
    "\n",
    "print(\"NMI {0:0.4f}\".format(nmi))\n",
    "print(\"ARI {0:0.4f}\".format(ari))\n",
    "\n",
    "# All series of words\n",
    "all_series = list()\n",
    "nbr_clust = len(np.unique(col_part))\n",
    "\n",
    "for n_clust in range(nbr_clust):\n",
    "    # Get the col and row indices corresponding to the current cluster\n",
    "    index_clust_col = np.where(col_part == n_clust)\n",
    "    index_clust_col = index_clust_col[0].flatten().tolist()\n",
    "    index_clust_row = np.where(row_part == n_clust)\n",
    "    index_clust_row = index_clust_row[0].flatten().tolist()\n",
    "        \n",
    "    # Extract the co-cluster and compute the count sum for all words of the co-cluster\n",
    "    curr_doc_term = doc_term_counts[index_clust_row,:]\n",
    "    curr_doc_term = curr_doc_term[:,index_clust_col]\n",
    "    tmp_terms_freq = (curr_doc_term.sum(axis=0))\n",
    "    print(\"n_clust\", n_clust, \"( row\", len(index_clust_row), \")\")\n",
    "    #print(curr_doc_term)\n",
    "\n",
    "    # Sort by decreasing count sum\n",
    "    tmp_order = (-tmp_terms_freq).argsort()\n",
    "    tmp_order = np.array(tmp_order[0]).flatten().tolist()\n",
    "    # Convert the ordered col index of the co-cluster into the original matrix index\n",
    "    tmp_order_org_idx = [index_clust_col[i] for i in tmp_order]\n",
    "        \n",
    "    curr_ppmi = mat_ppmi[:,tmp_order_org_idx[:n_top_terms]]\n",
    "    curr_ppmi = curr_ppmi[tmp_order_org_idx[:n_top_terms],:]\n",
    "    all_top_terms_idx.append(tmp_order_org_idx[:n_top_terms])\n",
    "    tmp_list = []\n",
    "    for i in range(curr_ppmi.shape[0]):\n",
    "        for j in range(i+1, curr_ppmi.shape[1]):\n",
    "            tmp_list.append(curr_ppmi[i,j])\n",
    "    tmp_mean = np.mean(tmp_list)\n",
    "    print(\"-->> PPMI:\", tmp_mean)\n",
    "      \n",
    "    # Convert to original index to get the words\n",
    "    tmp_org_idx = index_clust_col\n",
    "    tmp_terms = [pm10_terms[i] for i in tmp_org_idx]\n",
    "    \n",
    "    for str_w in [\"gout\", \"otiti\", \"jaundic\", \"triptan\", \n",
    "                  \"calculi\", \"raynaud\", \"chickenpox\", \"hepat\",\n",
    "                 \"macular\", \"allerg\"]:\n",
    "        res = [i for i in tmp_terms if str_w in i] \n",
    "        if len(res)>0:\n",
    "            print(res)\n",
    "    top_terms = [tmp_terms[i] for i in tmp_order[:n_top_terms]]\n",
    "    print(len(tmp_terms))\n",
    "    \n",
    "    # See the top terms\n",
    "    top_terms = np.stack(top_terms, axis = 0 )\n",
    "    print(\"-->\", top_terms, \"\\n\")\n",
    "    all_series.append(pd.Series(top_terms))\n",
    "\n",
    "if final_k == 10:\n",
    "    print(pd.concat([all_series[0], all_series[1], all_series[2], all_series[3], all_series[4],\n",
    "                     all_series[5], all_series[6], all_series[7], all_series[8], all_series[9]], axis=1))\n",
    "elif final_k == 9:\n",
    "    print(pd.concat([all_series[0], all_series[1], all_series[2], all_series[3], all_series[4],\n",
    "                     all_series[5], all_series[6], all_series[7], all_series[8]], axis=1))\n",
    "elif final_k == 8:\n",
    "    print(pd.concat([all_series[0], all_series[1], all_series[2], all_series[3], all_series[4],\n",
    "                     all_series[5], all_series[6], all_series[7]], axis=1))\n",
    "elif final_k == 7:\n",
    "    print(pd.concat([all_series[0], all_series[1], all_series[2], all_series[3], all_series[4],\n",
    "                    all_series[5], all_series[6]], axis=1))\n",
    "\n",
    "print(\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Clust 0\n",
      "-->> self PPMI: 1.2240339061614822\n",
      "-->> versus all PPMI: 0.13624255374752395\n",
      "\n",
      "# Clust 1\n",
      "-->> self PPMI: 0.896955059822908\n",
      "-->> versus all PPMI: 0.11312488786504223\n",
      "\n",
      "# Clust 2\n",
      "-->> self PPMI: 0.9764043279587383\n",
      "-->> versus all PPMI: 0.14901031574638657\n",
      "\n",
      "# Clust 3\n",
      "-->> self PPMI: 0.547273258256797\n",
      "-->> versus all PPMI: 0.09845708982568195\n",
      "\n",
      "# Clust 4\n",
      "-->> self PPMI: 1.46302530915902\n",
      "-->> versus all PPMI: 0.11897814335701283\n",
      "\n",
      "# Clust 5\n",
      "-->> self PPMI: 0.5935877510106102\n",
      "-->> versus all PPMI: 0.11131857030445105\n",
      "\n",
      "# Clust 6\n",
      "-->> self PPMI: 1.0207473592090734\n",
      "-->> versus all PPMI: 0.08091476493608557\n",
      "\n",
      "# Clust 7\n",
      "-->> self PPMI: 0.486066114834723\n",
      "-->> versus all PPMI: 0.1002459814905754\n",
      "\n",
      "# Clust 8\n",
      "-->> self PPMI: 1.0117519232181098\n",
      "-->> versus all PPMI: 0.12130651830715736\n",
      "\n",
      "# Clust 9\n",
      "-->> self PPMI: 0.9936665159194995\n",
      "-->> versus all PPMI: 0.0991590479391268\n"
     ]
    }
   ],
   "source": [
    "for i in range(nbr_clust):\n",
    "    print(\"\\n# Clust\", i)\n",
    "        \n",
    "    # PPMI\n",
    "    # ----\n",
    "    list_mean = list()\n",
    "    for j in range(nbr_clust):\n",
    "        curr_ppmi = mat_ppmi[:,all_top_terms_idx[i]]\n",
    "        curr_ppmi = curr_ppmi[all_top_terms_idx[j],:]\n",
    "        #tmp_mean = (np.triu(curr_ppmi.todense(), 1).sum())/(curr_ppmi.shape[0]*(curr_ppmi.shape[0]-1)/2)\n",
    "        tmp_list = []\n",
    "        for k in range(curr_ppmi.shape[0]):\n",
    "            for l in range(k+1, curr_ppmi.shape[1]):\n",
    "                tmp_list.append(curr_ppmi[k,l])\n",
    "        tmp_mean = np.mean(tmp_list)\n",
    "        if j != i: \n",
    "            list_mean.append(tmp_mean)\n",
    "        else:\n",
    "            print(\"-->> self PPMI:\", tmp_mean)\n",
    "    print(\"-->> versus all PPMI:\", np.mean(list_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPMI within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_terms=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import subprocess\n",
    "import re\n",
    "import os\n",
    "\n",
    "jar_path = '/home/saffeldt/Projects/Projects_clustering/DCC/Palmetto/palmetto-0.1.0-jar-with-dependencies.jar'\n",
    "wiki_file = '/home/saffeldt/Projects/Projects_clustering/DCC/Palmetto/Wikipedia_bd/wikipedia_bd'\n",
    "c_measure = 'npmi'\n",
    "topic_file = '/home/saffeldt/Projects/Projects_clustering/DCC/Palmetto/topic_files/current_topics.txt'\n",
    "out_file = '/home/saffeldt/Projects/Projects_clustering/DCC/Palmetto/topic_files/current_topics_out.txt'\n",
    "\n",
    "# PUBMED5 top terms\n",
    "word_list = ['wa', 'macular', 'eye', 'visual', 'amd', 'retinal', 'acuity', 'associate', 'degeneration', 'group']\n",
    "word_list = ['otitis', 'ear', 'child', 'media', 'middle', 'acute', 'antibiotics', 'aom', 'tube', 'om']\n",
    "word_list = ['stone', 'renal', 'calcium', 'urinary', 'kidney', 'oxalate', 'rate', 'urine', 'percutaneous', 'calculi']\n",
    "word_list = ['allergy', 'nasal', 'rhinitis', 'symptom', 'pollen', 'seasonal', 'effect', 'allergens', 'asthma', 'increase']\n",
    "word_list = ['migraine', 'patient', 'headache', 'study', 'thi', 'treatment', 'ar', 'pain', 'attack', 'associate']\n",
    "\n",
    "# AMD vs OTITIS\n",
    "word_list = [\"wa\", \"macular\", \"eye\", \"visual\", \"amd\", \"retinal\", \"acuity\", \"associate\", \"degeneration\", \n",
    "             \"group\", \"neovascular\", \"significant\", \"month\", \"diabetic\", \"no\", \"improve\", \"risk\", \n",
    "             \"choroiditis\", \"edema\", \"measure\", \"intravitreal\", \"result\", \"thick\", \"change\", \"injection\", \n",
    "             \"case\", \"evaluate\", \"development\", \"show\", \"factor\"]\n",
    "word_list = [\"otitis\",\"ear\",\"children\",\"media\",\"middle\",\"acute\",\"antibiotics\",\"aom\",\"tube\",\"om\",\"ag\",\n",
    "             \"hear\",\"effusion\",\"year\",\"chronic\",\"dai\",\"infection\",\"present\",\"cause\",\"isolate\",\n",
    "             \"recurrent\",\"pneumonia\",\"bacterial\",\"found\",\"tympan\",\"vaccin\",\"mastoiditis\",\"complication\",\n",
    "             \"pneumococcal\",\"influenza\"]\n",
    "word_list = [\"stone\",\"renal\",\"calcium\",\"urinary\",\"kidney\",\"oxalate\",\"rate\",\"urine\", \"percutaneous\",\n",
    "             \"calculi\",\"crystal\",\"lower\",\"shock\",\"lithotripsy\",\"wave\", \"fragment\",\"ureter\",\"acid\",\n",
    "             \"require\",\"excretion\",\"nephrolithotomy\",\"procedure\", \"formation\",\"protein\",\"material\",\n",
    "             \"tract\",\"management\",\"metabolite\",\"uric\",\"pcnl\"]\n",
    "word_list = [\"allergic\", \"nasal\", \"rhinitis\", \"symptom\", \"pollen\", \"seasonal\", \"effect\", \"allergen\", \n",
    "             \"asthma\", \"increase\", \"significantly\", \"subject\", \"score\", \"level\", \"cell\", \"ig\", \n",
    "             \"placebo\", \"allergy\", \"test\", \"sensitive\", \"specific\", \"total\", \"immunotherapy\", \n",
    "             \"active\", \"grass\", \"eosinophil\", \"intranasal\", \"reduce\", \"challenge\", \"daily\"]\n",
    "word_list = [\"migraine\", \"patient\", \"headache\", \"study\", \"thi\", \"treatment\", \"ar\", \"pain\", \"clinical\", \n",
    "             \"compare\", \"attack\", \"than\", \"may\", \"different\", \"dure\", \"aura\", \"report\", \"control\", \n",
    "             \"severe\", \"ha\", \"mg\", \"medical\", \"response\", \"efficacy\", \"sumatriptan\", \"assess\", \n",
    "             \"include\", \"data\", \"triptan\", \"drug\"]\n",
    "\n",
    "word_list = [\"macular\", \"degeneration\", \"retinal\", \"edema\", \"diabetic\", \"acuity\", \"visual\", \"amd\", \n",
    "                  \"injection\", \"eye\", \"neovascular\", \"risk\", \"factor\", \"intravitreal\", \"significant\", \n",
    "                  \"measure\", \"associate\", \"evaluate\", \"improve\", \"result\", \"change\", \"development\", \n",
    "                  \"case\", \"thick\", \"show\", \"choroiditis\", \"group\", \"month\", \"no\", \"wa\"]\n",
    "\n",
    "word_list = [\"calcium\", \"urinary\", \"gout\", \"oxalate\", \"crystal\", \"urine\", \"acid\", \"kidney\", \"uric\", \n",
    "             \"excrete\", \"serum\", \"protein\", \"urater\", \"format\", \"metabolite\", \"gouti\", \"normal\", \n",
    "             \"citrat\", \"concentr\", \"form\", \"low\", \"deposit\", \"male\", \"nephrolithiasi\", \"phosphat\", \n",
    "             \"diet\", \"dietari\", \"allopurinol\", \"joint\", \"collect\", \"hyperuricemia\", \"arthriti\", \n",
    "             \"tubular\", \"caox\", \"potassium\", \"ph\", \"plasma\", \"hypercalciuria\", \"magnesium\", \n",
    "             \"inhibitor\", \"tophi\", \"creatinin\", \"msu\", \"idiopath\", \"mice\", \"tophac\", \"supersatur\", \n",
    "             \"composit\", \"bind\", \"monosodium\"]\n",
    "\n",
    "n_words = len(word_list)\n",
    "n_pairs = int((n_words*(n_words-1)/2))\n",
    "\n",
    "all_npmi = np.zeros((n_words, n_words))\n",
    "\n",
    "# Call Palmetto/NPMI\n",
    "# ----\n",
    "cmd = \"java -jar '{}' '{}' '{}' '{}' > '{}'\".format(jar_path, wiki_file, c_measure, topic_file, out_file)\n",
    "for wi in range(n_words-1):\n",
    "    # Write all word pairs in a topic file\n",
    "    outF = open(topic_file, \"w\")\n",
    "    for wj in range(wi+1, n_words):\n",
    "        line = '{} {}\\n'.format(word_list[wi], word_list[wj])\n",
    "        outF.write(line)\n",
    "    outF.close()\n",
    "    \n",
    "    # Call Palmetto for NPMI\n",
    "    result = os.system(cmd)\n",
    "\n",
    "    if result == 0:\n",
    "        # Read out file line by line\n",
    "        file1 = open(out_file, 'r') \n",
    "        #next(file1)\n",
    "        Lines = file1.readlines()[1:]\n",
    "        \n",
    "        # Strips the newline character\n",
    "        for line in Lines: \n",
    "            tmp_list = line.strip().split()\n",
    "            #print(tmp_list)\n",
    "            tmp_value = tmp_list[1]\n",
    "            tmp_wi_str = (tmp_list[2])[1:-1]\n",
    "            tmp_wj_str = (tmp_list[3])[0:-1]\n",
    "            tmp_wi_idx = word_list.index(tmp_wi_str)\n",
    "            tmp_wj_idx = word_list.index(tmp_wj_str)\n",
    "            all_npmi[tmp_wi_idx, tmp_wj_idx] = tmp_value\n",
    "            all_npmi[tmp_wj_idx, tmp_wi_idx] = all_npmi[tmp_wi_idx, tmp_wj_idx]\n",
    "            #print(tmp_wi_str, tmp_wj_str, tmp_value)\n",
    "        \n",
    "#print(all_npmi)\n",
    "# Compute the NPMI3 scores\n",
    "k = 5\n",
    "all_npmi_argsort = np.argsort(-all_npmi, axis = 0)\n",
    "all_npmi_score = []\n",
    "\n",
    "for i_word in range(len(word_list)):\n",
    "    tmp_order_idx = all_npmi_argsort[:,i_word].flatten().tolist()\n",
    "    tmp_order_idx = [idx for idx in tmp_order_idx if idx != i_word ]\n",
    "    tmp_npmi_score = all_npmi[tmp_order_idx[:k], i_word]\n",
    "    print(i_word, word_list[i_word], \"--> \", [word_list[i] for i in tmp_order_idx[:k]], tmp_npmi_score)\n",
    "    all_npmi_score.append(np.mean(tmp_npmi_score))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "word_npmi_order_idx = np.argsort(-np.array(all_npmi_score))\n",
    "word_npmi_order_str_series = pd.Series([word_list[i] for i in word_npmi_order_idx])\n",
    "word_npmi_order_val_series = pd.Series([all_npmi_score[i] for i in word_npmi_order_idx])\n",
    "pd.concat([word_npmi_order_str_series, word_npmi_order_val_series], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all NPMI values as matrix\n",
    "np.savetxt(\"/home/saffeldt/Projects/Projects_clustering/DCC/output/PubMed5/NPMI/allNPMI_30w_k5_amd.csv\", all_npmi, \n",
    "              delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all pairwise average\n",
    "all_npmi_mean = (np.triu(all_npmi, 1).sum())/(all_npmi.shape[0]*(all_npmi.shape[0]-1)/2)\n",
    "print(\"# NPMI average: \", all_npmi_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPMIk between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "jar_path = '/home/saffeldt/Projects/Projects_clustering/DCC/Palmetto/palmetto-0.1.0-jar-with-dependencies.jar'\n",
    "wiki_file = '/home/saffeldt/Projects/Projects_clustering/DCC/Palmetto/Wikipedia_bd/wikipedia_bd'\n",
    "c_measure = 'npmi'\n",
    "topic_file = '/home/saffeldt/Projects/Projects_clustering/DCC/Palmetto/topic_files/current_topics.txt'\n",
    "out_file = '/home/saffeldt/Projects/Projects_clustering/DCC/Palmetto/topic_files/current_topics_out.txt'\n",
    "\n",
    "# PUBMED5 frequency top terms\n",
    "## -- 10 -- ##\n",
    "#word_list_amd = ['wa', 'macular', 'eye', 'visual', 'amd', 'retinal', 'acuity', 'associate', 'degeneration', 'group']\n",
    "##word_list_otitis = ['otitis', 'ear', 'children', 'media', 'middle', 'acute', 'antibiotics', 'aom', 'tube', 'om']\n",
    "#word_list_otitis = ['otitis', 'ear', 'child', 'media', 'middle', 'acute', 'antibiotics', 'aom', 'tube', 'om']\n",
    "#word_list_kidney = ['stone', 'renal', 'calcium', 'urinary', 'kidney', 'oxalate', 'rate', 'urine', 'percutaneous', 'calculi']\n",
    "#word_list_hayfever = ['allergy', 'nasal', 'rhinitis', 'symptom', 'pollen', 'seasonal', 'effect', 'allergens', 'asthma', 'increase']\n",
    "#word_list_migraine = ['migraine', 'patient', 'headache', 'study', 'thi', 'treatment', 'ar', 'pain', 'attack', 'associate']\n",
    "\n",
    "# PUBMED5 NPMIk top terms\n",
    "## -- 30 -- ##\n",
    "word_list_amd = [\"macular\", \"degeneration\", \"retinal\", \"edema\", \"diabetic\", \"acuity\", \"visual\", \"amd\", \n",
    "                  \"injection\", \"eye\", \"neovascular\", \"risk\", \"factor\", \"intravitreal\", \"significant\", \n",
    "                  \"measure\", \"associate\", \"evaluate\", \"improve\", \"result\", \"change\", \"development\", \n",
    "                  \"case\", \"thick\", \"show\", \"choroiditis\", \"group\", \"month\", \"no\", \"wa\"]\n",
    "word_list_otitis = [\"otitis\", \"infection\", \"pneumonia\", \"bacterial\", \"acute\", \"chronic\", \"antibiotics\", \n",
    "                    \"recurrent\", \"effusion\", \"complication\", \"influenza\", \"ear\", \"cause\", \"pneumococcal\", \n",
    "                    \"isolate\", \"media\", \"tube\", \"hear\", \"middle\", \"vaccin\", \"present\", \"found\", \"tympan\", \n",
    "                    \"mastoiditis\", \"children\", \"ag\", \"year\", \"aom\", \"dai\", \"om\"]\n",
    "word_list_kidney = [\"urinary\", \"excretion\", \"ureter\", \"urine\", \"kidney\", \"renal\", \"uric\", \"oxalate\", \n",
    "                    \"acid\", \"metabolite\", \"calcium\", \"lithotripsy\", \"tract\", \"calculi\", \"protein\", \n",
    "                    \"crystal\", \"stone\", \"percutaneous\", \"procedure\", \"shock\", \"wave\", \"lower\", \n",
    "                    \"formation\", \"nephrolithotomy\", \"rate\", \"fragment\", \"require\", \"material\", \n",
    "                    \"management\", \"pcnl\"]\n",
    "word_list_hayfever = [\"allergic\", \"rhinitis\", \"allergy\", \"asthma\", \"allergen\", \"immunotherapy\", \"pollen\", \"nasal\", \n",
    "                      \"symptom\", \"eosinophil\", \"cell\", \"seasonal\", \"effect\", \"sensitive\", \"placebo\", \"reduce\", \n",
    "                      \"increase\", \"test\", \"specific\", \"grass\", \"level\", \"subject\", \"total\", \"active\", \"daily\", \n",
    "                      \"intranasal\", \"score\", \"challenge\", \"ig\", \"significantly\"]\n",
    "word_list_migraine = [\"migraine\", \"headache\", \"triptan\", \"treatment\", \"pain\", \"patient\", \"efficacy\", \n",
    "                      \"clinical\", \"drug\", \"severe\", \"medical\", \"sumatriptan\", \"aura\", \"assess\", \"study\", \n",
    "                      \"compare\", \"data\", \"mg\", \"response\", \"attack\", \"control\", \"report\", \"may\", \n",
    "                      \"different\", \"ha\", \"include\", \"thi\", \"ar\", \"than\", \"dure\"]\n",
    "\n",
    "\n",
    "# One vs Others,\n",
    "word_list = word_list_migraine\n",
    "word_list.extend(word_list_hayfever)\n",
    "\n",
    "n_words = len(word_list)\n",
    "n_pairs = int((n_words*(n_words-1)/2))\n",
    "\n",
    "all_npmi = np.zeros((n_words, n_words))\n",
    "\n",
    "# Call Palmetto/NPMI\n",
    "# ----\n",
    "cmd = \"java -jar '{}' '{}' '{}' '{}' > '{}'\".format(jar_path, wiki_file, c_measure, topic_file, out_file)\n",
    "for wi in range(n_words-1):\n",
    "    print(\"# word\", wi)\n",
    "    # Write all word pairs in a topic file\n",
    "    outF = open(topic_file, \"w\")\n",
    "    for wj in range(wi+1, n_words):\n",
    "        line = '{} {}\\n'.format(word_list[wi], word_list[wj])\n",
    "        outF.write(line)\n",
    "    outF.close()\n",
    "    \n",
    "    # Call Palmetto for NPMI\n",
    "    result = os.system(cmd)\n",
    "\n",
    "    if result == 0:\n",
    "        # Read out file line by line\n",
    "        file1 = open(out_file, 'r') \n",
    "        #next(file1)\n",
    "        Lines = file1.readlines()[1:]\n",
    "        \n",
    "        # Strips the newline character\n",
    "        for line in Lines: \n",
    "            tmp_list = line.strip().split()\n",
    "            #print(tmp_list)\n",
    "            tmp_value = tmp_list[1]\n",
    "            tmp_wi_str = (tmp_list[2])[1:-1]\n",
    "            tmp_wj_str = (tmp_list[3])[0:-1]\n",
    "            tmp_wi_idx = word_list.index(tmp_wi_str)\n",
    "            tmp_wj_idx = word_list.index(tmp_wj_str)\n",
    "            all_npmi[tmp_wi_idx, tmp_wj_idx] = tmp_value\n",
    "            all_npmi[tmp_wj_idx, tmp_wi_idx] = all_npmi[tmp_wi_idx, tmp_wj_idx]\n",
    "            #print(tmp_wi_str, tmp_wj_str, tmp_value)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(all_npmi)\n",
    "# Compute the NPMIk scores\n",
    "k = 5\n",
    "#print(word_list)\n",
    "sub_npmi = all_npmi[n_top_terms:(2*n_top_terms),:n_top_terms]\n",
    "sub_npmi_argsort = np.argsort(-sub_npmi, axis = 0)\n",
    "sub_npmi_score = []\n",
    "\n",
    "for i_word in range(sub_npmi.shape[1]):\n",
    "    tmp_order_idx = sub_npmi_argsort[:,i_word].flatten().tolist()\n",
    "    tmp_npmi_score = sub_npmi[tmp_order_idx[:k], i_word]\n",
    "    print(i_word, word_list[i_word], \"--> \", [word_list[i+n_top_terms] for i in tmp_order_idx[:k]], \n",
    "          tmp_npmi_score)\n",
    "    sub_npmi_score.append(np.mean(tmp_npmi_score))\n",
    "\n",
    "import pandas as pd\n",
    "word_npmi_str_series = pd.Series(word_list[:n_top_terms])\n",
    "word_npmi_val_series = pd.Series(sub_npmi_score)\n",
    "pd.concat([word_npmi_str_series, word_npmi_val_series], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CosSim within coCluster from doc-term counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_top_terms=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "from sklearn.metrics.cluster import adjusted_rand_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "out_dir = \"/home/saffeldt/Projects/Projects_clustering/DCC/output\"\n",
    "data_name = \"PubMed5\"\n",
    "\n",
    "version = \"mulPPMI_ColW-RowZ\" # mulPPMI_Col, mulPPMI_Row, mulPPMI_ColZ-RowW, mulPPMI_ColW-RowZ\n",
    "#all_versions = [\"mulPPMI_Col\", \"mulPPMI_Row\", \"mulPPMI_ColZ-RowW\", \"mulPPMI_ColW-RowZ\", \"id\"]\n",
    "all_versions = [\"mulPPMI_ColZ-RowW\"]\n",
    "p = 1\n",
    "n_init = 10\n",
    "n_runs = 20\n",
    "    \n",
    "all_top_terms = dict()\n",
    "all_top_terms_idx = dict()\n",
    "\n",
    "for version in all_versions:\n",
    "    print(\"# Version\", version)\n",
    "    all_top_terms[version] = []\n",
    "    all_top_terms_idx[version] = []\n",
    "    \n",
    "    if version == \"id\":\n",
    "        p = 0\n",
    "        \n",
    "    # Load the column partition\n",
    "    col_part_path = os.path.join(out_dir, data_name, \"{}init_{}runs_p{}_{}\".format(n_init, n_runs, p, version), \"dcc_l2_sidfTrue_stfFalse_k5_stoch70_init10_iter100__axis1.npy\")\n",
    "    col_part = np.load(col_part_path)\n",
    "\n",
    "    # Load the row partition\n",
    "    row_part_path = os.path.join(out_dir, data_name, \"{}init_{}runs_p{}_{}\".format(n_init, n_runs, p, version), \"dcc_l2_sidfTrue_stfFalse_k5_stoch70_init10_iter100__axis0.npy\")\n",
    "    row_part = np.load(row_part_path)\n",
    "\n",
    "    # Select one of the co-clustering result\n",
    "    part_num = -1\n",
    "    best_nmi = 0.0\n",
    "\n",
    "    # Evaluate the row partition and select the partition with the best NMI\n",
    "    for i_part in range(n_runs):\n",
    "        ari = adjusted_rand_score(labels, row_part[i_part,:])\n",
    "        nmi = normalized_mutual_info_score(labels, row_part[i_part,:], average_method=\"arithmetic\")\n",
    "        #print(\"# --> ({}) NMI\".format(i_part), \"{0:.4f}\".format(nmi), \n",
    "        #      \"| ({}) ARI\".format(i_part), \"{0:.4f}\".format(ari), \"\\n\")\n",
    "\n",
    "        if nmi > best_nmi:\n",
    "            part_num =  i_part\n",
    "            best_nmi = nmi\n",
    "\n",
    "    print(\"{} Best row partition: {} | \".format(version, part_num), \"NMI {0:0.4f}\".format(best_nmi))\n",
    "\n",
    "    # All series of words\n",
    "    all_series = []\n",
    "    nbr_clust = len(np.unique(col_part))\n",
    "\n",
    "    for n_clust in range(nbr_clust):\n",
    "        print(\"n_clust\", n_clust)\n",
    "        # Get the col and row indices corresponding to the current cluster\n",
    "        index_clust_col = np.where(col_part[part_num,:] == n_clust)\n",
    "        index_clust_col = index_clust_col[0].flatten().tolist()\n",
    "        index_clust_row = np.where(row_part[part_num,:] == n_clust)\n",
    "        index_clust_row = index_clust_row[0].flatten().tolist()\n",
    "        \n",
    "        # Extract the co-cluster\n",
    "        curr_doc_term = mat[index_clust_row,:]\n",
    "        curr_doc_term = curr_doc_term[:,index_clust_col]\n",
    "        print(\"--> curr_doc_term.shape\", curr_doc_term.shape)\n",
    "        tmp_terms_freq = (curr_doc_term.sum(axis = 0))\n",
    "        tmp_terms_freq = tmp_terms_freq.flatten().tolist()\n",
    "        tmp_terms_freq = tmp_terms_freq[0]\n",
    "        print(\"--> tmp_terms_freq[:10]\", tmp_terms_freq[:10], len(tmp_terms_freq))\n",
    "        \n",
    "        # Sort by decreasing count sum\n",
    "        tmp_order = (-np.array(tmp_terms_freq)).argsort()\n",
    "        tmp_order = tmp_order.flatten().tolist()\n",
    "        print(\"--> tmp_order[:10]\", tmp_order[:10], len(tmp_order))\n",
    "        print(\"--> tmp freq order[:10]\", [tmp_terms_freq[i] for i in tmp_order[:10]])\n",
    "              \n",
    "        # Convert the ordered col index of the co-cluster into the original matrix index\n",
    "        tmp_order_org_idx = [index_clust_col[i] for i in tmp_order]\n",
    "        \n",
    "        # Convert to original index to get the words\n",
    "        tmp_org_idx = (word_org_idx[index_clust_col]).tolist()\n",
    "        tmp_terms = [pm10_terms[i] for i in tmp_org_idx]\n",
    "        top_terms = [tmp_terms[i] for i in tmp_order[:n_top_terms]]    \n",
    "\n",
    "        # See the top terms\n",
    "        top_terms = np.stack(top_terms, axis = 0 )\n",
    "        print(\"-->\", top_terms, \"\\n\")\n",
    "        \n",
    "        # Compute dot product\n",
    "        # Reorder doc-term sub mat\n",
    "        curr_doc_term = curr_doc_term[:,tmp_order]        \n",
    "        curr_doc_term = normalize(curr_doc_term, norm='l2', axis = 0)       \n",
    "        Sc = curr_doc_term.T * curr_doc_term\n",
    "        Sc = Sc[:n_top_terms,:n_top_terms]\n",
    "        #print(\"MIN\", np.min(np.triu(Sc.todense(), 1)))\n",
    "        #print(np.triu(Sc.todense(), 1))\n",
    "        #print(Sc.todense())\n",
    "        #print(\"MAX\", np.max(np.triu(Sc.todense(), 1)))\n",
    "        tmp_list = []\n",
    "        for i in range(n_top_terms):\n",
    "            for j in range(i+1, n_top_terms):\n",
    "                if Sc[i,j] > 0.0:\n",
    "                    tmp_list.append(Sc[i,j])\n",
    "                    print(top_terms[i], top_terms[j], Sc[i,j])\n",
    "                \n",
    "        tmp_mean = np.mean(tmp_list)\n",
    "        print(\"-->> Mean CosSim:\", tmp_mean, '\\n')\n",
    "                \n",
    "        \n",
    "    #print(pd.concat([all_series[0], all_series[1], all_series[2], all_series[3], all_series[4]], axis=1))\n",
    "    #print(\"\\n\")\n",
    "    #import matplotlib.pyplot as plt\n",
    "    #plt.plot(tmp_terms_freq[:,tmp_order][0][:,:500])\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
