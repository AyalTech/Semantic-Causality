{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use this notebook to generate a PubMed dataset from PubMed10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Origin of the PubMed10 dataset\n",
    "# http://www-personal.umich.edu/~chenyanh/ev_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classes to be selected\n",
    "# For PubMed5: \n",
    "#  (6) Hay Fever --> nDoc = 1517\n",
    "#  (7) Kidney Calculi --> nDoc = 1549\n",
    "#  (8) Age-related Macular Degeneration --> nDoc = 3283\n",
    "#  (9) Migraine --> nDoc = 3703\n",
    "# (10) Otitis --> nDoc = 2596\n",
    "classes_select = [6, 7, 8, 9, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PubMed10 document-term data\n",
    "PubMed10_dw = loadmat(\"../../../../data/PubMed10/docWordMat.mat\")\n",
    "doc_term_counts = PubMed10_dw[\"docWordMat\"]\n",
    "\n",
    "# Load PubMed10 document true labels\n",
    "PubMed10_lb = loadmat(\"../../../../data/PubMed10/label.mat\")\n",
    "labels = PubMed10_lb[\"label\"]\n",
    "labels = [item for sublist in labels for item in sublist]\n",
    "\n",
    "# Load the words\n",
    "pm10_terms = loadmat(\"../../../../data/PubMed10/wordList.mat\")\n",
    "pm10_terms = pm10_terms[\"wordList\"]\n",
    "pm10_terms_list = list()\n",
    "\n",
    "for i in range(pm10_terms.shape[0]):\n",
    "    pm10_terms_list.append(pm10_terms[i,0].tolist()[0])\n",
    "pm10_terms = pm10_terms_list\n",
    "\n",
    "# Identify labels for PubMed5\n",
    "PubMed5_lb_unique = classes_select\n",
    "PubMed5_idx = list()\n",
    "for searchval in PubMed5_lb_unique:\n",
    "    PubMed5_idx.extend(np.where(np.asarray(labels) == searchval)[0])\n",
    "\n",
    "# Reduce the labels list\n",
    "labels = [labels[i] for i in PubMed5_idx]\n",
    "\n",
    "# Reduce the doc_term_counts matrix with the list of document index\n",
    "doc_term_counts = doc_term_counts[np.asarray(PubMed5_idx), :]\n",
    "\n",
    "# Reduce the doc_term_counts matrix by removing columns of 0\n",
    "word_org_idx = np.unique(doc_term_counts.nonzero()[1])\n",
    "doc_term_counts = doc_term_counts[:, np.unique(doc_term_counts.nonzero()[1])]\n",
    "\n",
    "# Get the corresponding terms\n",
    "terms = [pm10_terms[i] for i in word_org_idx]\n",
    "terms = np.asarray(terms)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the document-term matrix\n",
    "sparse.save_npz('../../../../data/PubMed5/PubMed5_docWordMat.npz', doc_term_counts) \n",
    "\n",
    "# Save the labels\n",
    "df = pd.DataFrame(labels, columns=[\"labels\"])\n",
    "df.to_csv('../../../../data/PubMed5/PubMed5_label.csv', index=False)\n",
    "\n",
    "# Save the terms\n",
    "df = pd.DataFrame(terms, columns=[\"terms\"])\n",
    "df.to_csv('../../../../data/PubMed5/PubMed5_wordList.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc-term shape:  (12648, 19518)\n",
      "nb docs: 12648\n",
      "nb terms: 19518\n"
     ]
    }
   ],
   "source": [
    "# How to load from files ?\n",
    "# ----------------\n",
    "# Doc-term\n",
    "doc_term_counts = sparse.load_npz('../../../../data/PubMed5/PubMed5_docWordMat.npz')\n",
    "print(\"# --> doc-term shape: \", doc_term_counts.shape)\n",
    "# Labels\n",
    "labels_df = pd.read_csv('../../../../data/PubMed5/PubMed5_label.csv', \n",
    "                     usecols = [0], delim_whitespace = True)\n",
    "labels = labels_df.values.flatten()\n",
    "print(\"# --> nb docs:\", len(labels))\n",
    "# Terms\n",
    "terms_df = pd.read_csv('../../../../data/PubMed5/PubMed5_wordList.csv', \n",
    "                     usecols = [0], delim_whitespace = True)\n",
    "terms = terms_df.values.flatten()\n",
    "print(\"# --> nb terms:\", len(terms))\n",
    "# ----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
